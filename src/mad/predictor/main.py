import asyncio
import asyncpg
import aiohttp
import yaml
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timezone
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam, RMSprop

async def create_db_pool():
    return await asyncpg.create_pool(
        user="mad",
        password="secretPASSW0rd",
        database="ml_models",
        host="80.93.60.49",
        port=30000,
    )

def iso_to_timestamp(iso_date):
    if isinstance(iso_date, datetime):
        dt = iso_date
    else:
        dt = datetime.strptime(iso_date, "%Y-%m-%dT%H:%M:%SZ")
    return int(dt.timestamp() * 1000)

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
def load_config(path="config.yaml"):
    with open(path, "r") as f:
        return yaml.safe_load(f)

config = load_config()

# === 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ VictoriaMetrics ===
async def fetch_metric_data(metric_name: str, db_pool, config: dict) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ VictoriaMetrics –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏.
    """
    async with db_pool.acquire() as conn:
        metric = await conn.fetchrow("""
            SELECT id, query, step FROM metrics 
            WHERE name = $1
        """, metric_name)

    if not metric:
        raise ValueError(f"Metric '{metric_name}' not found in database")

    url = f"{config['system']['victoriametrics_url']}/query_range"
    params = {
        "query": metric["query"],
        "start": iso_to_timestamp(datetime.now(timezone.utc) - 3600 * 1000),  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        "end": iso_to_timestamp(datetime.now(timezone.utc)),
        "step": f"{metric['step']}s"
    }

    async with aiohttp.ClientSession() as session:
        async with session.get(url, params=params) as resp:
            result = await resp.json()

        try:
            values = result["data"]["result"][0]["values"]
        except (KeyError, IndexError):
            raise RuntimeError(f"No data returned for metric {metric_name}")

        df = pd.DataFrame(values, columns=["timestamp", "value"])
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="s")
        df["value"] = df["value"].astype(float)
        return df.set_index("timestamp")

# === 3. –û–±—É—á–µ–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏ ===
async def train_lstm_model(dataframe: pd.DataFrame, model_config: dict):
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    window_size = model_config.get("window_size", 10)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    scaler = StandardScaler()
    scaled_values = scaler.fit_transform(dataframe[["value"]])
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    X, y = [], []
    for i in range(len(scaled_values) - window_size):
        X.append(scaled_values[i:i + window_size])
        y.append(scaled_values[i + window_size])
    
    X = np.array(X)
    y = np.array(y)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation
    split_idx = int(len(X) * (1 - model_config.get("validation_split", 0.2)))
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = Sequential()
    
    # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π
    first_layer_units = model_config["layers"][0]["units"]
    model.add(LSTM(
        first_layer_units,
        input_shape=(window_size, 1),
        return_sequences=len(model_config["layers"]) > 1
    ))
    
    # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å–ª–æ–∏
    for layer in model_config["layers"][1:]:
        if layer["type"] == "LSTM":
            model.add(LSTM(
                layer["units"],
                return_sequences=layer.get("return_sequences", False)
            ))
        elif layer["type"] == "Dense":
            model.add(Dense(layer["units"]))
    
    if model_config.get("dropout"):
        model.add(Dropout(model_config["dropout"]))
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
    model.add(Dense(1))
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
    optimizer = Adam(learning_rate=model_config["learning_rate"]) if model_config["optimizer"] == "adam" \
        else RMSprop(learning_rate=model_config["learning_rate"])
    model.compile(loss=model_config["loss"], optimizer=optimizer)
    
    # –û–±—É—á–µ–Ω–∏–µ
    history = model.fit(
        X_train, y_train,
        epochs=model_config["epochs"],
        batch_size=model_config["batch_size"],
        validation_data=(X_val, y_val),
        verbose=1
    )
    
    return {
        "model": model,
        "config": model_config,
        "scaler": scaler,
        "history": history.history,
        "window_size": window_size
    }

# === 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
async def save_model(model_name: str, model, model_info, db_pool):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    """
    async with db_pool.acquire() as conn:
        # –ü–æ–ª—É—á–∞–µ–º ID –º–æ–¥–µ–ª–∏
        model_id = await conn.fetchval("""
            SELECT id FROM models WHERE name = $1
        """, model_name)
        
        if not model_id:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            model_id = await conn.fetchval("""
                INSERT INTO models(
                    name, 
                    max_stored_versions, 
                    hyperparams_mode, 
                    status, 
                    active_version,
                    training_start,
                    training_end
                )
                VALUES($1, $2, $3, $4, $5, $6, $7)
                RETURNING id
            """, 
            model_name,
            5,  # default max_stored_versions
            "manual",  # –∏–ª–∏ "optuna" –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥–∞
            "active",
            "1.0",
            datetime.now(timezone.utc),
            datetime.now(timezone.utc))

        # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ scaler
        model_data = pickle.dumps({
            'model': model,
            'scaler': model_info['scaler'],
            'window_size': model_info['window_size']
        })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏
        await conn.execute("""
            INSERT INTO models_version(
                model_data, 
                version, 
                model_id, 
                hyperparams
            )
            VALUES($1, $2, $3, $4)
        """, 
        model_data,
        "1.0",  # –ú–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        model_id,
        json.dumps(model_info['config']))

# === 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ ===
async def process_model(queue, config, db_pool):
    while True:
        model_name = await queue.get()
        print(f"üöÄ Start training for model: {model_name}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
            model_config = next(
                m for m in config["mad_predictor"]["models"] 
                if m["name"] == model_name
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É
            main_metric = model_config["main_metric"]
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            data = await fetch_metric_data(main_metric, db_pool, config)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            training_result = await train_lstm_model(
                data, 
                model_config.get("manual_params", {})
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            await save_model(
                model_name,
                training_result["model"],
                {
                    "config": training_result["config"],
                    "scaler": training_result["scaler"],
                    "window_size": training_result["window_size"]
                },
                db_pool
            )
            
            print(f"‚úÖ Model saved for: {model_name}")
            
        except Exception as e:
            print(f"‚ùå Error processing model {model_name}: {str(e)}")
            
        finally:
            queue.task_done()

# === 6. –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤ ===
async def run_training_queue(queue, config, db_pool):
    workers = [
        asyncio.create_task(process_model(queue, config, db_pool)) 
        for _ in range(config["system"].get("workers", 3))
    ]
    await asyncio.gather(*workers)

# === 7. –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ–±—ã—Ç–∏—è PostgreSQL ===
async def listen_for_models(queue, config, db_pool):
    async def handle_notify(conn, pid, channel, payload):
        print(f"üì° Notification received on {channel}: {payload}")
        try:
            model_id = int(payload)
        except ValueError:
            print("‚ö†Ô∏è Invalid payload:", payload)
            return
            
        async with db_pool.acquire() as conn:
            model = await conn.fetchrow("""
                SELECT id, name FROM models 
                WHERE id = $1 AND status = 'active'
            """, model_id)

            if model:
                await queue.put(model["name"])
                print(f"üì• Model {model['name']} added to queue")
            else:
                print(f"‚è≠ Model {model_id} is inactive or not found")

    conn = await asyncpg.connect(dsn=config["system"]["db_conn_string"])
    await conn.add_listener('new_active_model', lambda conn, pid, channel, payload:
        asyncio.create_task(handle_notify(conn, pid, channel, payload)))

    print("üëÇ Listening for 'new_active_model' notifications...")

    while True:
        await asyncio.sleep(3600)  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∂–∏–≤–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è

# === 8. –ì–ª–∞–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ ===
async def main():
    config = load_config()
    db_pool = await create_db_pool()
    
    queue = asyncio.Queue()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    for model in config["mad_predictor"]["models"]:
        await queue.put(model["name"])
    
    await asyncio.gather(
        listen_for_models(queue, config, db_pool),
        run_training_queue(queue, config, db_pool)
    )

if __name__ == "__main__":
    asyncio.run(main())