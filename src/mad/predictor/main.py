import asyncio
import asyncpg
import aiohttp
import yaml
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timezone
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam, RMSprop

async def create_db_pool():
    return await asyncpg.create_pool(
        user="mad",
        password="secretPASSW0rd",
        database="ml_models",
        host="80.93.60.49",
        port=30000,
    )

def iso_to_timestamp(iso_date):
    if isinstance(iso_date, datetime):
        dt = iso_date
    else:
        dt = datetime.strptime(iso_date, "%Y-%m-%dT%H:%M:%SZ")
    return int(dt.timestamp() * 1000)

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
def load_config(path="config.yaml"):
    with open(path, "r") as f:
        return yaml.safe_load(f)

config = load_config()

# === 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ VictoriaMetrics ===
async def fetch_metric_data(metric_name: str, db_pool, config: dict) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ VictoriaMetrics –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏.
    """
    async with db_pool.acquire() as conn:
        metric = await conn.fetchrow("""
            SELECT id, query, step FROM metrics 
            WHERE name = $1
        """, metric_name)
    print("VM get metricsssssssssssssss")
    if not metric:
        raise ValueError(f"Metric '{metric_name}' not found in database")

    url = f"{config['system']['victoriametrics_url']}/query_range"
    params = {
        "query": metric["query"],
        "start": iso_to_timestamp(datetime.now(timezone.utc) - 3600 * 1000),  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        "end": iso_to_timestamp(datetime.now(timezone.utc)),
        "step": f"{metric['step']}s"
    }

    async with aiohttp.ClientSession() as session:
        async with session.get(url, params=params) as resp:
            result = await resp.json()

        try:
            values = result["data"]["result"][0]["values"]
        except (KeyError, IndexError):
            raise RuntimeError(f"No data returned for metric {metric_name}")

        df = pd.DataFrame(values, columns=["timestamp", "value"])
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="s")
        df["value"] = df["value"].astype(float)
        return df.set_index("timestamp")

# === 3. –û–±—É—á–µ–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏ ===
async def train_lstm_model(dataframe: pd.DataFrame, model_config: dict):
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    window_size = model_config.get("window_size", 10)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    scaler = StandardScaler()
    scaled_values = scaler.fit_transform(dataframe[["value"]])
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    X, y = [], []
    for i in range(len(scaled_values) - window_size):
        X.append(scaled_values[i:i + window_size])
        y.append(scaled_values[i + window_size])
    
    X = np.array(X)
    y = np.array(y)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation
    split_idx = int(len(X) * (1 - model_config.get("validation_split", 0.2)))
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = Sequential()
    
    # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π
    first_layer_units = model_config["layers"][0]["units"]
    model.add(LSTM(
        first_layer_units,
        input_shape=(window_size, 1),
        return_sequences=len(model_config["layers"]) > 1
    ))
    
    # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å–ª–æ–∏
    for layer in model_config["layers"][1:]:
        if layer["type"] == "LSTM":
            model.add(LSTM(
                layer["units"],
                return_sequences=layer.get("return_sequences", False)
            ))
        elif layer["type"] == "Dense":
            model.add(Dense(layer["units"]))
    
    if model_config.get("dropout"):
        model.add(Dropout(model_config["dropout"]))
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
    model.add(Dense(1))
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
    optimizer = Adam(learning_rate=model_config["learning_rate"]) if model_config["optimizer"] == "adam" \
        else RMSprop(learning_rate=model_config["learning_rate"])
    model.compile(loss=model_config["loss"], optimizer=optimizer)
    
    # –û–±—É—á–µ–Ω–∏–µ
    history = model.fit(
        X_train, y_train,
        epochs=model_config["epochs"],
        batch_size=model_config["batch_size"],
        validation_data=(X_val, y_val),
        verbose=1
    )
    
    return {
        "model": model,
        "config": model_config,
        "scaler": scaler,
        "history": history.history,
        "window_size": window_size
    }

# === 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
async def save_model(model_name: str, model, model_info, db_pool):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    """
    async with db_pool.acquire() as conn:
        # –ü–æ–ª—É—á–∞–µ–º ID –º–æ–¥–µ–ª–∏
        model_id = await conn.fetchval("""
            SELECT id FROM models WHERE name = $1
        """, model_name)
        print("1")
        if not model_id:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            model_id = await conn.fetchval("""
                INSERT INTO models(
                    name, 
                    max_stored_versions, 
                    hyperparams_mode, 
                    status, 
                    active_version,
                    training_start,
                    training_end
                )
                VALUES($1, $2, $3, $4, $5, $6, $7)
                RETURNING id
            """, 
            model_name,
            5,  # default max_stored_versions
            "manual",  # –∏–ª–∏ "optuna" –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥–∞
            "active",
            "1.0",
            datetime.now(timezone.utc),
            datetime.now(timezone.utc))
        print("2")
        # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ scaler
        model_data = pickle.dumps({
            'model': model,
            'scaler': model_info['scaler'],
            'window_size': model_info['window_size']
        })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏
        await conn.execute("""
            INSERT INTO models_version(
                model_data, 
                version, 
                model_id, 
                hyperparams
            )
            VALUES($1, $2, $3, $4)
        """, 
        model_data,
        "1.0",  # –ú–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        model_id,
        json.dumps(model_info['config']))

# === 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ ===
async def process_model(queue, db_pool):
    while True:
        model_id = await queue.get()
        print(f"üöÄ Start processing model with ID: {model_id}")
        print("3")
        async with db_pool.acquire() as conn:
            try:
                # –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
                async with conn.transaction():
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ 'training'
                    model = await conn.fetchrow("""
                        UPDATE models 
                        SET status = 'training' 
                        WHERE id = $1 
                        RETURNING id, name, metric_id, hyperparams_mode, 
                                    training_start, training_end
                    """, model_id)
                    print("4")
                    if not model:
                        print(f"‚è≠ Model {model_id} not found")
                        continue
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É
                    main_metric = await conn.fetchrow("""
                        SELECT id, name, query, step 
                        FROM metrics 
                        WHERE id = $1 AND status = 'active'
                    """, model['metric_id'])
                    print("5")
                    if not main_metric:
                        print(f"‚è≠ Main metric for model {model['name']} not found or inactive")
                        await conn.execute("UPDATE models SET status = 'deactive' WHERE id = $1", model_id)
                        continue
                    print("6")
                    # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Ñ–∏—á–∏)
                    features = await conn.fetch("""
                        SELECT m.id, m.name, m.query, m.step 
                        FROM features f
                        JOIN metrics m ON f.metric_id = m.id
                        WHERE f.model_id = $1 AND m.status = 'active'
                    """, model_id)
                    print("7")
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ (–æ—Å–Ω–æ–≤–Ω–∞—è + —Ñ–∏—á–∏)
                    all_metrics = [main_metric] + [dict(f) for f in features]
                    print("8")
                    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
                    manual_params = {}
                    if model['hyperparams_mode'] == 'manual':
                        manual_params = await conn.fetchrow("""
                            SELECT * FROM models_version 
                            WHERE model_id = $1 AND is_active = true
                        """, model_id)
                        manual_params = dict(manual_params) if manual_params else {}
                    print("9")
                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
                    metric_data = []
                    for metric in all_metrics:
                        data = await fetch_metric_data(
                            metric['query'],
                            metric['step'],
                            model['training_start'],
                            model['training_end'],
                            db_pool
                        )
                        metric_data.append(data)
                    
                    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                    training_result = await train_lstm_model(
                        metric_data,
                        manual_params
                    )
                    print("10")
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                    await save_model(
                        model['id'],
                        training_result["model"],
                        {
                            "config": training_result["config"],
                            "scaler": training_result["scaler"],
                            "window_size": training_result["window_size"]
                        },
                        db_pool
                    )
                    print("11")
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏ –Ω–∞ 'active'
                    await conn.execute("""
                        UPDATE models 
                        SET status = 'active', 
                            active_version = $2,
                            training_start = NOW(),
                            training_end = NOW()
                        WHERE id = $1
                    """, model_id, str(training_result["version"]))
                    print("12")
                    print(f"‚úÖ Model {model['name']} (ID: {model_id}) successfully trained and saved")
            
            except Exception as e:
                print(f"‚ùå Error processing model {model_id}: {str(e)}")
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Å—Ç–∞—Ç—É—Å 'active' –∏–ª–∏ 'waiting'
                try:
                    await conn.execute("""
                        UPDATE models 
                        SET status = CASE 
                            WHEN status = 'training' THEN 'active' 
                            ELSE status 
                        END
                        WHERE id = $1
                    """, model_id)
                except Exception as update_err:
                    print(f"‚ö†Ô∏è Failed to update model status: {update_err}")
            
            finally:
                queue.task_done()

# === 6. –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤ ===
async def run_training_queue(queue, config, db_pool):
    print("122")
    workers = [
        asyncio.create_task(process_model(queue, db_pool)) 
        for _ in range(config["system"].get("workers", 3))
    ]
    await asyncio.gather(*workers)

# === 7. –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ–±—ã—Ç–∏—è PostgreSQL ===
async def listen_for_models(queue, config, db_pool):
    async def handle_notify(conn, pid, channel, payload):
        print(f"üì° Notification received on {channel}: {payload}")
        try:
            model_id = int(payload)
        except ValueError:
            print("‚ö†Ô∏è Invalid payload:", payload)
            return
            
        async with db_pool.acquire() as conn:
            model = await conn.fetchrow("""
                SELECT id, name FROM models 
                WHERE id = $1 AND status = 'waiting'
            """, model_id)

            if model:
                await queue.put(model["id"])
                print(f"üì• Model {model['name']} added to queue")
            else:
                print(f"‚è≠ Model {model_id} is inactive or not found")

    conn = await asyncpg.connect(dsn=config["system"]["db_conn_string"])
    await conn.add_listener('model_training_queue', lambda conn, pid, channel, payload:
        asyncio.create_task(handle_notify(conn, pid, channel, payload)))

    print("üëÇ Listening for 'model_training_queue' notifications...")

    while True:
        await asyncio.sleep(3600)  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∂–∏–≤–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è

# === 8. –ì–ª–∞–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ ===
async def main():
    config = load_config()
    db_pool = await create_db_pool()
    
    queue = asyncio.Queue()

    await asyncio.gather(
        listen_for_models(queue, config, db_pool),
        run_training_queue(queue, config, db_pool)
    )

if __name__ == "__main__":
    asyncio.run(main())